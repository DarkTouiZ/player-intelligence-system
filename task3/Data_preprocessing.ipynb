{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387502b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dc1909d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983c7bdb",
   "metadata": {},
   "source": [
    "# Type casting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "074c9ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "float_columns = ['event_participation_rate', 'avg_session_length', 'sessions_per_week', 'total_playtime_hours', 'days_since_last_login',\n",
    "'historical_spending', 'prev_month_spending', 'avg_transaction_value', 'days_since_last_purchase', 'purchase_frequency']\n",
    "\n",
    "cat_columns = ['guild_membership', 'is_premium_member', 'primary_game', 'platform', 'owns_limited_edition', 'tournament_participation', 'segment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "74ea6b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast categorical columns\n",
    "for col in cat_columns:\n",
    "    train_df[col] = train_df[col].astype('category')\n",
    "    test_df[col] = test_df[col].astype('category')\n",
    "\n",
    "# Cast float columns (ไว้เป็น float)\n",
    "for col in float_columns:\n",
    "    train_df[col] = train_df[col].astype('float64')\n",
    "    test_df[col] = test_df[col].astype('float64')\n",
    "\n",
    "# Cast ที่เหลือเป็น int\n",
    "all_columns = set(train_df.select_dtypes(include=['float64']).columns)\n",
    "exclude_columns = set(float_columns + cat_columns + ['spending_30d'])  # เผื่อ target เป็น float\n",
    "int_columns = list(all_columns - exclude_columns)\n",
    "\n",
    "for col in int_columns:\n",
    "    train_df[col] = train_df[col].fillna(-1).astype('int64')\n",
    "    test_df[col] = test_df[col].fillna(-1).astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac319033",
   "metadata": {},
   "source": [
    "# Prerpocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e455c9",
   "metadata": {},
   "source": [
    "## Handle Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f66408d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer, SimpleImputer\n",
    "\n",
    "iter_imputer = IterativeImputer(max_iter=10, random_state=2025)\n",
    "\n",
    "# Initial\n",
    "all_num_cols = float_columns + int_columns\n",
    "special_columns = [col for col in all_num_cols if train_df[col].min() == -1]\n",
    "train_df[special_columns] = train_df[special_columns].replace(-1, np.nan)\n",
    "test_df[special_columns] = test_df[special_columns].replace(-1, np.nan)\n",
    "\n",
    "# Fit and transform\n",
    "train_df[all_num_cols] = iter_imputer.fit_transform(train_df[all_num_cols])\n",
    "test_df[all_num_cols] = iter_imputer.transform(test_df[all_num_cols])\n",
    "\n",
    "# categorical column\n",
    "cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "train_df[cat_columns] = cat_imputer.fit_transform(train_df[cat_columns])\n",
    "test_df[cat_columns] = cat_imputer.transform(test_df[cat_columns])\n",
    "train_df[cat_columns] = train_df[cat_columns].astype('category')\n",
    "test_df[cat_columns] = test_df[cat_columns].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "61a06e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(train_df.isnull().sum().sum())\n",
    "print(test_df.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75450de6",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2d82966d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "def feature_engineering(df):\n",
    "    df_ = df.copy()\n",
    "\n",
    "    # ========== Log Transform ==========\n",
    "    df_['historical_spending_log'] = np.log1p(df_['historical_spending'])\n",
    "    df_['prev_month_spending_log'] = np.log1p(df_['prev_month_spending'])\n",
    "    df_['avg_transaction_value_log'] = np.log1p(df_['avg_transaction_value'])\n",
    "    df_['total_playtime_hours_log'] = np.log1p(df_['total_playtime_hours'])\n",
    "\n",
    "    # ========== Cyclical Encoding ==========\n",
    "    df_['seasonal_sin'] = np.sin(df_['seasonal_spending_pattern'] * (2 * np.pi / 12))\n",
    "    df_['seasonal_cos'] = np.cos(df_['seasonal_spending_pattern'] * (2 * np.pi / 12))\n",
    "\n",
    "    # ========== Spending Behavior Features ==========\n",
    "    # Average spending per transaction\n",
    "    df_['spend_per_transaction'] = df_['historical_spending'] / (df_['total_transactions'] + 1)\n",
    "    \n",
    "    # Spending momentum (prev month vs historical average)\n",
    "    df_['spending_trend'] = df_['prev_month_spending'] / (df_['historical_spending'] / 12 + 1)\n",
    "    \n",
    "    # Purchase recency score (inverse of days since last purchase)\n",
    "    df_['purchase_recency'] = 1 / (df_['days_since_last_purchase'] + 1)\n",
    "    \n",
    "    # Discount affinity (how much they use discounts)\n",
    "    df_['discount_affinity'] = df_['purchases_on_discount'] / (df_['total_transactions'] + 1)\n",
    "\n",
    "    # Purchase velocity (change in spending rate)\n",
    "    df_['purchase_velocity'] = (\n",
    "        df_['prev_month_spending'] - (df_['historical_spending'] / 12)\n",
    "    ) / (df_['historical_spending'] / 12 + 1)\n",
    "\n",
    "    # Spending acceleration (change in spending relative to avg transaction)\n",
    "    df_['spending_acceleration'] = (\n",
    "        df_['prev_month_spending'] - df_['avg_transaction_value']\n",
    "    ) / (df_['avg_transaction_value'] + 1)\n",
    "    \n",
    "    # ========== Engagement Features ==========\n",
    "    # Session intensity (playtime per session)\n",
    "    df_['session_intensity'] = df_['total_playtime_hours'] / (df_['sessions_per_week'] * 52 + 1)\n",
    "    \n",
    "    # Activity recency (inverse of days since last login)\n",
    "    df_['login_recency'] = 1 / (df_['days_since_last_login'] + 1)\n",
    "    \n",
    "    # Engagement consistency (login streak relative to account age)\n",
    "    df_['engagement_consistency'] = df_['daily_login_streak'] / (df_['account_age_days'] + 1)\n",
    "\n",
    "    # Engagement decay (days since last login relative to login streak)\n",
    "    df_['engagement_decay'] = df_['days_since_last_login'] / (df_['daily_login_streak'] + 1)\n",
    "\n",
    "    df_['total_activity_score'] = (\n",
    "        df_['sessions_per_week'] * \n",
    "        df_['avg_session_length'] * \n",
    "        df_['daily_login_streak']\n",
    "    )\n",
    "    \n",
    "    df_['social_activity_ratio'] = (\n",
    "        df_['social_interactions'] / \n",
    "        (df_['sessions_per_week'] * 52 + 1)\n",
    "    )\n",
    "\n",
    "    # ========== Social Features ==========\n",
    "    # Social engagement rate\n",
    "    df_['social_engagement'] = df_['social_interactions'] / (df_['friend_count'] + 1)\n",
    "\n",
    "    # ========== Achievement Features ==========\n",
    "    # Achievement velocity (achievements per day of account age)\n",
    "    df_['achievement_velocity'] = df_['achievement_count'] / (df_['account_age_days'] + 1)\n",
    "\n",
    "    # ========== Cross-Game Features ==========\n",
    "    # Game diversity (games played relative to cross-game activity)\n",
    "    df_['game_diversity'] = df_['games_played'] / (df_['cross_game_activity'] + 1)\n",
    "\n",
    "    # ========== Transaction Patterns ==========\n",
    "    # Transaction frequency score\n",
    "    df_['transaction_frequency_score'] = df_['purchase_frequency'] * df_['total_transactions']\n",
    "    \n",
    "    # High value spender flag (above 75th percentile in avg transaction)\n",
    "    df_['is_high_value_spender'] = (\n",
    "        df_['avg_transaction_value'] > df_['avg_transaction_value'].quantile(0.75)\n",
    "    ).astype(int).astype('category')\n",
    "\n",
    "    # FIX: Convert category to numeric before arithmetic operations\n",
    "    df_['premium_engagement'] = (\n",
    "        (df_['is_premium_member'].cat.codes + df_['vip_status']) * \n",
    "        df_['avg_session_length']\n",
    "    )\n",
    "    \n",
    "    df_['value_consistency'] = df_['avg_transaction_value'] / (df_['historical_spending'] / (df_['total_transactions'] + 1))\n",
    "\n",
    "    # ========== Interaction Features ==========\n",
    "    # Engagement × Spending (active spenders)\n",
    "    df_['engagement_x_spending'] = (\n",
    "        (df_['sessions_per_week'] * df_['avg_session_length']) * \n",
    "        df_['prev_month_spending_log']\n",
    "    )\n",
    "    \n",
    "    # Social × Spending (social spenders)\n",
    "    df_['social_x_spending'] = df_['social_interactions'] * df_['prev_month_spending_log']\n",
    "    \n",
    "    # Event participation × VIP (premium event participants)\n",
    "    df_['event_x_vip'] = df_['event_participation_rate'] * df_['vip_status']\n",
    "\n",
    "    # Behavioral Segments\n",
    "    df_['whale_potential'] = (\n",
    "        df_['vip_status'] * \n",
    "        np.log1p(df_['avg_transaction_value']) * \n",
    "        df_['purchase_frequency']\n",
    "    )\n",
    "\n",
    "    # Churn Risk Score\n",
    "    df_['churn_risk_score'] = (\n",
    "        df_['days_since_last_login'] * \n",
    "        df_['days_since_last_purchase'] / \n",
    "        (df_['daily_login_streak'] + 1)\n",
    "    )\n",
    "\n",
    "    # ====== Efficiency Ratios ======\n",
    "    df_['achievement_per_playtime'] = df_['achievement_count'] / (df_['total_playtime_hours'] + 1)\n",
    "    df_['social_to_friend_ratio'] = df_['social_interactions'] / (df_['friend_count'] + 1)\n",
    "    df_['discount_dependency'] = df_['purchases_on_discount'] / (df_['total_transactions'] + 1)\n",
    "    df_['playtime_per_session'] = df_['total_playtime_hours'] / (df_['sessions_per_week'] * 52 + 1)\n",
    "\n",
    "    # ====== Binning Features ======\n",
    "    df_['account_age_bin'] = pd.cut(\n",
    "        df_['account_age_days'], \n",
    "        bins=[0, 180, 365, 730, np.inf],\n",
    "        labels=['new', 'medium', 'veteran', 'ancient'],\n",
    "        include_lowest=True\n",
    "    ).astype('category')\n",
    "\n",
    "    df_['playtime_bin'] = pd.cut(\n",
    "        df_['total_playtime_hours'],\n",
    "        bins=[0, 100, 500, 1000, np.inf],\n",
    "        labels=['casual', 'regular', 'hardcore', 'extreme'],\n",
    "        include_lowest=True\n",
    "    ).astype('category')\n",
    "\n",
    "    return df_\n",
    "\n",
    "train_feat_df = feature_engineering(train_df)\n",
    "test_feat_df = feature_engineering(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "67945fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3108\n",
      "3108\n"
     ]
    }
   ],
   "source": [
    "print(train_feat_df.isnull().sum().sum())\n",
    "print(train_feat_df.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "39508e99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['historical_spending_log', 'prev_month_spending_log',\n",
       "       'avg_transaction_value_log', 'discount_affinity',\n",
       "       'engagement_x_spending', 'social_x_spending', 'whale_potential',\n",
       "       'discount_dependency'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feat_df.columns[train_feat_df.isnull().any()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5590d4f9",
   "metadata": {},
   "source": [
    "# Encode Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "12caa5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns = train_feat_df.select_dtypes(include=['category']).columns\n",
    "\n",
    "def encode_categorical(df):\n",
    "    df_ = df.copy()\n",
    "    # One-hot encode categorical features\n",
    "    df_ = pd.get_dummies(df_, columns=cat_columns, drop_first=True)\n",
    "    return df_\n",
    "\n",
    "train_encode_df = encode_categorical(train_feat_df)\n",
    "test_encode_df = encode_categorical(test_feat_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f31deb45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>player_id</th>\n",
       "      <th>friend_count</th>\n",
       "      <th>social_interactions</th>\n",
       "      <th>event_participation_rate</th>\n",
       "      <th>daily_login_streak</th>\n",
       "      <th>avg_session_length</th>\n",
       "      <th>sessions_per_week</th>\n",
       "      <th>total_playtime_hours</th>\n",
       "      <th>days_since_last_login</th>\n",
       "      <th>...</th>\n",
       "      <th>segment_1.0</th>\n",
       "      <th>segment_2.0</th>\n",
       "      <th>segment_3.0</th>\n",
       "      <th>is_high_value_spender_1</th>\n",
       "      <th>account_age_bin_medium</th>\n",
       "      <th>account_age_bin_veteran</th>\n",
       "      <th>account_age_bin_ancient</th>\n",
       "      <th>playtime_bin_regular</th>\n",
       "      <th>playtime_bin_hardcore</th>\n",
       "      <th>playtime_bin_extreme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ANS00001</td>\n",
       "      <td>P128956</td>\n",
       "      <td>177.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>33.157419</td>\n",
       "      <td>138.0</td>\n",
       "      <td>143.414888</td>\n",
       "      <td>7.151850</td>\n",
       "      <td>1051.879412</td>\n",
       "      <td>10.598046</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ANS00002</td>\n",
       "      <td>P115227</td>\n",
       "      <td>55.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>27.683671</td>\n",
       "      <td>54.0</td>\n",
       "      <td>253.827162</td>\n",
       "      <td>31.460513</td>\n",
       "      <td>433.186064</td>\n",
       "      <td>4.108231</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ANS00003</td>\n",
       "      <td>P013087</td>\n",
       "      <td>28.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>75.184955</td>\n",
       "      <td>101.0</td>\n",
       "      <td>114.896217</td>\n",
       "      <td>34.737910</td>\n",
       "      <td>669.426704</td>\n",
       "      <td>0.015370</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ANS00004</td>\n",
       "      <td>P045326</td>\n",
       "      <td>79.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>17.440872</td>\n",
       "      <td>15.0</td>\n",
       "      <td>119.473134</td>\n",
       "      <td>12.991553</td>\n",
       "      <td>729.958232</td>\n",
       "      <td>0.616083</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ANS00005</td>\n",
       "      <td>P052078</td>\n",
       "      <td>121.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>52.693562</td>\n",
       "      <td>4.0</td>\n",
       "      <td>176.099045</td>\n",
       "      <td>12.882396</td>\n",
       "      <td>520.605664</td>\n",
       "      <td>3.948152</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id player_id  friend_count  social_interactions  \\\n",
       "0  ANS00001   P128956         177.0                 71.0   \n",
       "1  ANS00002   P115227          55.0                 99.0   \n",
       "2  ANS00003   P013087          28.0                 69.0   \n",
       "3  ANS00004   P045326          79.0                 78.0   \n",
       "4  ANS00005   P052078         121.0                 84.0   \n",
       "\n",
       "   event_participation_rate  daily_login_streak  avg_session_length  \\\n",
       "0                 33.157419               138.0          143.414888   \n",
       "1                 27.683671                54.0          253.827162   \n",
       "2                 75.184955               101.0          114.896217   \n",
       "3                 17.440872                15.0          119.473134   \n",
       "4                 52.693562                 4.0          176.099045   \n",
       "\n",
       "   sessions_per_week  total_playtime_hours  days_since_last_login  ...  \\\n",
       "0           7.151850           1051.879412              10.598046  ...   \n",
       "1          31.460513            433.186064               4.108231  ...   \n",
       "2          34.737910            669.426704               0.015370  ...   \n",
       "3          12.991553            729.958232               0.616083  ...   \n",
       "4          12.882396            520.605664               3.948152  ...   \n",
       "\n",
       "   segment_1.0  segment_2.0  segment_3.0  is_high_value_spender_1  \\\n",
       "0         True        False        False                    False   \n",
       "1         True        False        False                    False   \n",
       "2        False        False         True                     True   \n",
       "3        False        False        False                    False   \n",
       "4        False         True        False                    False   \n",
       "\n",
       "   account_age_bin_medium  account_age_bin_veteran  account_age_bin_ancient  \\\n",
       "0                    True                    False                    False   \n",
       "1                   False                    False                     True   \n",
       "2                   False                     True                    False   \n",
       "3                    True                    False                    False   \n",
       "4                   False                    False                     True   \n",
       "\n",
       "   playtime_bin_regular  playtime_bin_hardcore  playtime_bin_extreme  \n",
       "0                 False                  False                  True  \n",
       "1                  True                  False                 False  \n",
       "2                 False                   True                 False  \n",
       "3                 False                   True                 False  \n",
       "4                 False                   True                 False  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_encode_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "58aa0523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "851\n",
      "851\n"
     ]
    }
   ],
   "source": [
    "print(test_encode_df.isnull().sum().sum())\n",
    "print(test_encode_df.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4488363b",
   "metadata": {},
   "source": [
    "# Scale Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a54f605f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "target_column = 'spending_30d'\n",
    "float_columns = train_encode_df.select_dtypes(include=['float64']).columns.difference([target_column])\n",
    "\n",
    "scaler = RobustScaler()\n",
    "\n",
    "train_scale_df = train_encode_df.copy()\n",
    "test_scale_df = test_encode_df.copy()\n",
    "train_scale_df[float_columns] = scaler.fit_transform(train_encode_df[float_columns])\n",
    "test_scale_df[float_columns] = scaler.transform(test_encode_df[float_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "80778d20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25889, 80)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_scale_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a52aa0",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6dc3fe8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drop 'prev_month_spending' (corr with 'historical_spending': 0.996)\n",
      "Drop 'historical_spending_log' (corr with 'prev_month_spending_log': 0.998)\n",
      "Drop 'purchase_velocity' (corr with 'spending_trend': 1.000)\n",
      "Drop 'social_engagement' (corr with 'social_to_friend_ratio': 1.000)\n",
      "Drop 'discount_affinity' (corr with 'discount_dependency': 1.000)\n",
      "Drop 'session_intensity' (corr with 'playtime_per_session': 1.000)\n",
      "\n",
      "Original features: 81\n",
      "Reduced features Train: 75\n",
      "Reduced features Test: 74\n",
      "Features removed: 6\n"
     ]
    }
   ],
   "source": [
    "def remove_high_correlation(df, threshold=0.9, target_col='spending_30d'):\n",
    "    # Get numeric columns only (exclude target and IDs)\n",
    "    exclude_cols = [target_col, 'id', 'player_id']\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    numeric_cols = [col for col in numeric_cols if col not in exclude_cols]\n",
    "    \n",
    "    # Calculate correlation matrix\n",
    "    corr_matrix = df[numeric_cols].corr().abs()\n",
    "    \n",
    "    # Get upper triangle (to avoid duplicates)\n",
    "    upper_triangle = corr_matrix.where(\n",
    "        np.triu(np.ones(corr_matrix.shape), k=1).astype(bool)\n",
    "    )\n",
    "    \n",
    "    # Find features with correlation > threshold\n",
    "    to_drop = []\n",
    "    for column in upper_triangle.columns:\n",
    "        # Find correlations above threshold\n",
    "        correlated_features = upper_triangle[column][upper_triangle[column] > threshold]\n",
    "        \n",
    "        if len(correlated_features) > 0:\n",
    "            # Check correlation with target to decide which to keep\n",
    "            for corr_feature in correlated_features.index:\n",
    "                if corr_feature not in to_drop and column not in to_drop:\n",
    "                    # Keep the one with higher correlation to target\n",
    "                    corr_col_target = abs(df[column].corr(df[target_col]))\n",
    "                    corr_feat_target = abs(df[corr_feature].corr(df[target_col]))\n",
    "                    \n",
    "                    if corr_col_target >= corr_feat_target:\n",
    "                        to_drop.append(corr_feature)\n",
    "                        print(f\"Drop '{corr_feature}' (corr with '{column}': {upper_triangle.loc[corr_feature, column]:.3f})\")\n",
    "                    else:\n",
    "                        to_drop.append(column)\n",
    "                        print(f\"Drop '{column}' (corr with '{corr_feature}': {upper_triangle.loc[corr_feature, column]:.3f})\")\n",
    "                        break\n",
    "    \n",
    "    # Remove duplicates\n",
    "    to_drop = list(set(to_drop))\n",
    "    \n",
    "    # Drop features\n",
    "    df_reduced = df.drop(columns=to_drop)\n",
    "    \n",
    "    return df_reduced, to_drop\n",
    "\n",
    "train_reduced, dropped_features = remove_high_correlation(train_scale_df, threshold=0.95, target_col='spending_30d')\n",
    "test_reduced = test_scale_df.drop(columns=dropped_features)\n",
    "\n",
    "print(f\"\\nOriginal features: {train_scale_df.shape[1]}\")\n",
    "print(f\"Reduced features Train: {train_reduced.shape[1]}\")\n",
    "print(f\"Reduced features Test: {test_reduced.shape[1]}\")\n",
    "print(f\"Features removed: {len(dropped_features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cd5cf416",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_final = train_reduced.copy()\n",
    "test_final = test_reduced.copy()\n",
    "\n",
    "train_final.to_csv(\"train_preprocessed_v4.csv\", index=False)\n",
    "test_final.to_csv(\"test_preprocessed_v4.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ce2ff54e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 features correlated with 'spending_30d':\n",
      "1. 'historical_spending' (corr=0.866)\n",
      "2. 'segment_3.0' (corr=0.727)\n",
      "3. 'prev_month_spending_log' (corr=0.629)\n",
      "4. 'whale_potential' (corr=0.579)\n",
      "5. 'event_x_vip' (corr=0.579)\n",
      "6. 'is_high_value_spender_1' (corr=0.533)\n",
      "7. 'avg_transaction_value_log' (corr=0.513)\n",
      "8. 'event_participation_rate' (corr=0.506)\n",
      "9. 'vip_status' (corr=0.452)\n",
      "10. 'premium_engagement' (corr=0.435)\n"
     ]
    }
   ],
   "source": [
    "target_col = 'spending_30d'\n",
    "corr_with_target = train_reduced.drop(columns=['id', 'player_id']).corr()[target_col].drop(target_col).abs()\n",
    "top_10_corr = corr_with_target.sort_values(ascending=False).head(10)\n",
    "print(f\"Top 10 features correlated with '{target_col}':\")\n",
    "for idx, (feature, corr_value) in enumerate(top_10_corr.items(), 1):\n",
    "    print(f\"{idx}. '{feature}' (corr={corr_value:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9d4449",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
